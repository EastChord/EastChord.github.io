<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>Regret Minimization | EastChord&#39;s Blog</title>
<meta name="keywords" content="">
<meta name="description" content="Regret minimization is a method to find optimal strategy in simultaneous games such as Rock-Paper-Scissors (RPS for short). We are going to explain what regret minimization is, especially the definition and how to use it, and we implement regret minimization through RPS game using Python.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:1313/posts/regret-minimization/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.40a1354939e65ba6e23c71b7275829cddd76ddbcf4fa5f5a240c00fe7cd0e8f8.css" integrity="sha256-QKE1STnmW6biPHG3J1gpzd123bz0&#43;l9aJAwA/nzQ6Pg=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/regret-minimization/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css" integrity="sha384-GvrOXuhMATgEsSwCs4smul74iXGOixntILdUW9XmUC6+HX0sLNAK3q71HotJqlAn" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js" integrity="sha384-cpW21h6RZv/phavutF+AuVYrr+dA8xD9zs6FwLpaCct6O9ctzYFfFr4dgmgccOTx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
        delimiters: [
            {left: '$$', right: '$$', display: true},
            {left: '$', right: '$', display: false},
            {left: '\\(', right: '\\)', display: false},
            {left: '\\[', right: '\\]', display: true}
        ],
        throwOnError: false
    });
});
</script>

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="EastChord&#39;s Blog (Alt + H)">EastChord&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:1313/posts/my-first-post/" title="About Me">
                    <span>About Me</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/cryptography/" title="Cryptography">
                    <span>Cryptography</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/categories/game-theory/" title="Game Theory">
                    <span>Game Theory</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:1313/search/" title="Search">
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Regret Minimization
    </h1>
    <div class="post-meta"><span title='2025-10-09 00:00:00 +0000 UTC'>October 9, 2025</span>

</div>
  </header> 
  <div class="post-content"><p>Regret minimization is a method to find optimal strategy in simultaneous games such as Rock-Paper-Scissors (RPS for short). We are going to explain what regret minimization is, especially the definition and how to use it, and we implement regret minimization through RPS game using Python.</p>
<p>Note that I didn&rsquo;t use complex words in this post such as Nash Equilibrium, Extensive Form Game, and so on. In this post, I used more abstract words such as Optimal, modify, etc. because I consider that the reader is a beginner at game theory. If you want more mathematical, formal and detailed text, read this <a href="https://www.ma.imperial.ac.uk/~dturaev/neller-lanctot.pdf">document</a>.</p>
<h2 id="what-is-regret">What is Regret<a hidden class="anchor" aria-hidden="true" href="#what-is-regret">#</a></h2>
<p>Let&rsquo;s play RPS betting money. We are both betting 1 dollar. If you win this game, then you can take all the money that we bet. Conversely, I can take all the money if I win. Suppose that you are rock and I am paper. You lost 1 dollar. If you play Paper instead of Rock, then you would not lose money. If you play Scissors, then you would even get money.</p>
<p><strong>Regret</strong> is defined as the gap between your payoff about your current action and your payoff about your other action. In the above situation, your payoff is $-1$ because you lose. But if you had been paper, this game would be a draw and your payoff would be $0$. So your regret is $0 - (-1) = 1$. If you had been scissors, you would win. So your payoff would be $1$ and the regret is $1 - (-1) = 2$.</p>
<h2 id="what-is-regret-minimization">What is Regret Minimization<a hidden class="anchor" aria-hidden="true" href="#what-is-regret-minimization">#</a></h2>
<p>The question is: can you optimize your strategy by using this regret information? Let&rsquo;s think about the easiest way first. What if you will do the action that has the biggest regret? For example, you can take scissors in the above situation. Unfortunately, it doesn&rsquo;t work well. Because I can easily know what you will take and I also modify my strategy: taking rock. So, just tracking the regret is not a good strategy.</p>
<p>Now we modify your strategy a little bit. What if you take rock, scissors, and paper probabilistically in proportion to regret? You will be able to take scissors with high probability, take paper with middle probability, and take rock with low probability. This is different from the first strategy. I will be able to take rock because I think you would take scissors, but I would be able to lose because you can take paper sometimes.</p>
<p>In this strategy, we can compute the probability of each action by dividing the summations of regret. For example, we have $3$ total regret in the first RPS game. Because the regret of Paper action is $1$, we would play Paper in the next game with probability $1/3$. Similarly, we would play Scissors with probability $2/3$ because the regret of Scissors is $2$. Therefore, our next strategy is $(\textsf{rock, paper, scissors}) = (0, 1/3, 2/3)$.</p>
<p>Using this strategy, suppose we are in the next game. Our RPS strategy is $(0, 1/3, 2/3)$ as we got before. In this game, suppose that you play scissors with $2/3$ probability and your opponent plays rock. We lose again. <del>I think the most optimal strategy is just to quit the game.</del> As before, we can compute the regret for each action. Your regret is $(1, 2, 0)$ for this game. Now we are going to modify our strategy by using regret.</p>
<p>How to modify our strategy? We are going to <em>accumulate</em> current regret into the regret we have gotten up to now. We had regret $(0, 1, 2)$ before. We will be able to have accumulated regret $(1, 3, 2)$ by adding the current regret $(1, 2, 0)$ to each action respectively. Now we can generate a new strategy by using accumulated regret. That is $(1/6, 3/6, 2/6)$.</p>
<p>By repeating this process a lot, a player <strong>minimizes</strong> expected regret. If the player reaches the minimum expected regret closely, then we can say this player&rsquo;s strategy is almost optimal. Note that Regret Minimization is an approximate method and this can&rsquo;t find the best strategy.</p>
<h2 id="how-to-implement-regret-minimization">How to Implement Regret Minimization<a hidden class="anchor" aria-hidden="true" href="#how-to-implement-regret-minimization">#</a></h2>
<p>In this section, we are going to implement a simulation of RPS game with two players that use Regret Minimization. We will use Python3 language. If you want to see the whole code, come to <a href="https://github.com/EastChord/Counterfactual-Regret-Minimization">my GitHub repository</a>.</p>
<p>If you run my RPS game simulations, then you can get an output that two players&rsquo; strategy is approximately $(0.333, 0.333, 0.333)$. Theoretically, the best strategy in a general RPS game is to play anything with the same probability.</p>
<h2 id="summary-and-future-post">Summary and Future Post<a hidden class="anchor" aria-hidden="true" href="#summary-and-future-post">#</a></h2>
<p>In this post, we learn what Regret Minimization is by using an RPS example. Regret is the difference between the payoff a player actually gets and the payoff a player could get if they acted differently. If a player minimizes this expected regret, then the player&rsquo;s strategy is near an optimal strategy. We can see the result of RPS game with two players using Regret Minimization and an optimal strategy in this game is to play with the same probability.</p>
<p>This Regret Minimization method can be used in simultaneous games such as RPS game. It means that we can&rsquo;t use this method in sequential games such as Poker. Fortunately, we can use another similar method called Counterfactual Regret Minimization. And maybe my next post is about this. Thank you.</p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">EastChord&#39;s Blog</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
